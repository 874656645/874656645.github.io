<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Welcome to Rick&#39;s Page  | Scrapy_Learn</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">

    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.52" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="/rick/dist/css/app.955516233bcafa4d2a1c13cea63c7b50.css" rel="stylesheet">
    

    

    
      
    

    

    <meta property="og:title" content="Scrapy_Learn" />
<meta property="og:description" content="原文网址
Using a virtual environment (recommended) pip install virtualenv  详细操作
Creating a new Scrapy project scrapy startproject tutorial
Writing a spider to crawl a site and extract data This is the code for our first Spider. Save it in a file named _quotesspider.py under the tutorial/spiders directory in your project:
import scrapy class QuotesSpider(scrapy.Spider): name = &quot;quotes&quot; def start_requests(self): urls = [ &#39;http://quotes.toscrape.com/page/1/&#39;, &#39;http://quotes.toscrape.com/page/2/&#39;, ] for url in urls: yield scrapy." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://874656645.github.io/rick/posts/scrapy_learn/" /><meta property="article:published_time" content="2019-02-15T15:40:48&#43;08:00"/>
<meta property="article:modified_time" content="2019-02-15T15:40:48&#43;08:00"/>

<meta itemprop="name" content="Scrapy_Learn">
<meta itemprop="description" content="原文网址
Using a virtual environment (recommended) pip install virtualenv  详细操作
Creating a new Scrapy project scrapy startproject tutorial
Writing a spider to crawl a site and extract data This is the code for our first Spider. Save it in a file named _quotesspider.py under the tutorial/spiders directory in your project:
import scrapy class QuotesSpider(scrapy.Spider): name = &quot;quotes&quot; def start_requests(self): urls = [ &#39;http://quotes.toscrape.com/page/1/&#39;, &#39;http://quotes.toscrape.com/page/2/&#39;, ] for url in urls: yield scrapy.">


<meta itemprop="datePublished" content="2019-02-15T15:40:48&#43;08:00" />
<meta itemprop="dateModified" content="2019-02-15T15:40:48&#43;08:00" />
<meta itemprop="wordCount" content="320">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Scrapy_Learn"/>
<meta name="twitter:description" content="原文网址
Using a virtual environment (recommended) pip install virtualenv  详细操作
Creating a new Scrapy project scrapy startproject tutorial
Writing a spider to crawl a site and extract data This is the code for our first Spider. Save it in a file named _quotesspider.py under the tutorial/spiders directory in your project:
import scrapy class QuotesSpider(scrapy.Spider): name = &quot;quotes&quot; def start_requests(self): urls = [ &#39;http://quotes.toscrape.com/page/1/&#39;, &#39;http://quotes.toscrape.com/page/2/&#39;, ] for url in urls: yield scrapy."/>

  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://874656645.github.io/rick/" class="f3 fw2 hover-white no-underline white-90 dib">
      Welcome to Rick&#39;s Page
    </a>
    <div class="flex-l items-center">
      
      
<div hidden>
  <span id="new-window-0">Opens in a new window</span>
  <span id="new-window-1">Opens an external site</span>
  <span id="new-window-2">Opens an external site in a new window</span>
</div>









    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3 ph0-l">

    <header class="mt4 w-100">
      <p class="f6 b helvetica tracked">
          
        POSTS
      </p>
      <h1 class="f1 athelas mb1">Scrapy_Learn</h1>
      
      <time class="f6 mv4 dib tracked" datetime="2019-02-15T15:40:48&#43;08:00">February 15, 2019</time>      
      
      
    </header>

    <main class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l">

<p><a href="https://docs.scrapy.org/en/latest/intro/tutorial.html">原文网址</a></p>

<h1 id="using-a-virtual-environment-recommended">Using a virtual environment (recommended)</h1>

<p><code>pip install virtualenv</code> <br/>
<a href="https://874656645.github.io/rick/posts/python-virtualenv/">详细操作</a></p>

<h1 id="creating-a-new-scrapy-project">Creating a new Scrapy project</h1>

<p><code>scrapy startproject tutorial</code></p>

<h1 id="writing-a-spider-to-crawl-a-site-and-extract-data">Writing a spider to crawl a site and extract data</h1>

<p>This is the code for our first Spider. Save it in a file named <strong>_quotes<em>spider.py</em></strong> under the <strong><em>tutorial/spiders</em></strong> directory in your project:</p>

<pre><code>import scrapy

class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;

    def start_requests(self):
        urls = [
            'http://quotes.toscrape.com/page/1/',
            'http://quotes.toscrape.com/page/2/',
        ]
        for url in urls:
            yield scrapy.Request(url=url, callback=self.parse)

    def parse(self, response):
        page = response.url.split(&quot;/&quot;)[-2]
        filename = 'quotes-%s.html' % page
        with open(filename, 'wb') as f:
            f.write(response.body)
        self.log('Saved file %s' % filename)
</code></pre>

<h2 id="extracting-data-in-our-spider">Extracting data in our spider</h2>

<pre><code>import scrapy

class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;
    start_urls = [
        'http://quotes.toscrape.com/page/1/',
        'http://quotes.toscrape.com/page/2/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }
</code></pre>

<h2 id="storing-the-scraped-data">Storing the scraped data</h2>

<p><code>scrapy crawl quotes -o quotes.json</code> <br/>
or <br/>
<code>scrapy crawl quotes -o quotes.jl</code></p>

<h1 id="exporting-the-scraped-data-using-the-command-line">Exporting the scraped data using the command line</h1>

<p><code>scrapy crawl quotes</code></p>

<h1 id="changing-spider-to-recursively-follow-links">Changing spider to recursively follow links</h1>

<pre><code>import scrapy


class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;
    start_urls = [
        'http://quotes.toscrape.com/page/1/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            next_page = response.urljoin(next_page)
            yield scrapy.Request(next_page, callback=self.parse)
</code></pre>

<h2 id="a-shortcut-for-creating-requests">A shortcut for creating Requests</h2>

<pre><code>import scrapy

class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;
    start_urls = [
        'http://quotes.toscrape.com/page/1/',
    ]

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('span small::text').get(),
                'tags': quote.css('div.tags a.tag::text').getall(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, callback=self.parse)
</code></pre>

<h1 id="using-spider-arguments">Using spider arguments</h1>

<p><code>scrapy crawl quotes -o quotes-humor.json -a tag=humor</code>
<br/></p>

<pre><code>import scrapy

class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;

    def start_requests(self):
        url = 'http://quotes.toscrape.com/'
        tag = getattr(self, 'tag', None)
        if tag is not None:
            url = url + 'tag/' + tag
        yield scrapy.Request(url, self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, self.parse)
</code></pre>
<ul class="pa0">
  
</ul>
<div class="mt6">
        
      </div>
    </main>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://874656645.github.io/rick/" >
    &copy; 2019 Welcome to Rick&#39;s Page
  </a>
    <div>
<div hidden>
  <span id="new-window-0">Opens in a new window</span>
  <span id="new-window-1">Opens an external site</span>
  <span id="new-window-2">Opens an external site in a new window</span>
</div>








</div>
  </div>
</footer>

    

  <script src="/rick/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
